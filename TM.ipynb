{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQfdnFGl2LH7hdmIeEzUj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriariit/COVID-19-Twitter-Data-Analysis/blob/master/TM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22gZmBm86I0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset=pd.read_csv(\"https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xbSWwP86qVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "spacy.load('en')\n",
        "from spacy.lang.en import English\n",
        "parser = English()\n",
        "\n",
        "def tokenize(text):\n",
        "    lda_tokens = []\n",
        "    tokens = parser(text)\n",
        "    for token in tokens:\n",
        "        if token.orth_.isspace():\n",
        "            continue\n",
        "        elif token.like_url:\n",
        "            lda_tokens.append('URL')\n",
        "        elif token.orth_.startswith('@'):\n",
        "            lda_tokens.append('SCREEN_NAME')\n",
        "        else:\n",
        "            lda_tokens.append(token.lower_)\n",
        "    return lda_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aeVTBDb6t_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "71ef28f8-0cc5-4673-9c0f-a67c82a90376"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i42DxcdQ69rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "def get_lemma(word):\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "        return lemma\n",
        "    \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "def get_lemma2(word):\n",
        "     return WordNetLemmatizer().lemmatize(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew2uAXcr7QRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3da26ea-6ae3-4a51-da16-951cf797ac00"
      },
      "source": [
        "for w in ['dogs', 'ran', 'discouraged']:\n",
        "    print(w, get_lemma(w), get_lemma2(w))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs dog dog\n",
            "ran run ran\n",
            "discouraged discourage discouraged\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ovggZwR7mXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bfca67dd-250f-49c9-f9bc-368c8d3fc09d"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQVRdEQC7twi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_text_for_lda(text):\n",
        "    tokens = tokenize(text)\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in en_stop]\n",
        "    tokens = [get_lemma(token) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TlPDein74qP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "d545249f-0f31-4b66-bf82-38e66632b4ba"
      },
      "source": [
        "import random\n",
        "text_data = []\n",
        "with open('dataset.csv') as f:\n",
        "    for line in f:\n",
        "        tokens = prepare_text_for_lda(line)\n",
        "        if random.random() > .99:\n",
        "            print(tokens)\n",
        "            text_data.append(tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['enchant', 'scissors', 'scissor', 'interface', 'support', 'cutting', 'interactive', 'fabrication']\n",
            "['generalize', 'arbitrary', 'resize', 'video', 'transcoding']\n",
            "['proposal', 'blind', 'equalizer', 'using', 'output', 'signal', 'decision', 'device']\n",
            "['frequency', 'response', 'masking', 'base', 'reconfigurable', 'channel', 'filter', 'software', 'radio', 'receiver']\n",
            "['piezoelectric', 'actuator', 'driver', 'circuit', 'automatic', 'focusing', 'mobile', 'phone', 'camera']\n",
            "['definition', 'evaluation', 'access', 'rule', 'management', 'system']\n",
            "['generic', 'solution', 'warehousing', 'business', 'process']\n",
            "['normalization', 'optimization', 'schema', 'mapping']\n",
            "['locating', 'source', 'large', 'distribute', 'system']\n",
            "['bilateral', 'filter', 'display', 'dynamic', 'range', 'image']\n",
            "['selectivity', 'estimation', 'extensible', 'database', 'neural', 'network', 'approach']\n",
            "['double', 'insertion', 'enhance', 'architecture', 'clock', 'route', 'reliability']\n",
            "['annotating', 'search', 'table', 'using', 'entity', 'type', 'relationship']\n",
            "['breath', 'energy']\n",
            "['sampling', 'bias', 'topology', 'measurement']\n",
            "['stereoscopic', 'conversion', 'pipeline', 'carter']\n",
            "['measuring', 'availability', 'domain', 'system']\n",
            "['multimode', 'digital', 'controller', 'power', 'management']\n",
            "['extend', 'counting', '32-channel', 'neural', 'recording', 'headstage', 'small', 'animal']\n",
            "['senbazuru', 'prototype', 'spreadsheet', 'database', 'management', 'system']\n",
            "['heavy', 'tail', 'g/1-ps', 'queue', 'impatience', 'admission', 'control', 'packet', 'network']\n",
            "['frequency', 'response', 'masking', 'base', 'filter', 'dection', 'wearable', 'biomedical', 'devices']\n",
            "['scalable', 'modulation', 'scalable', 'wireless', 'videocast']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ZgTO2l9wTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYSTk99W-G49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in text_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b72A6_qk-Y-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1e66d2a2-482e-4234-c230-146b32701bd3"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
        "dictionary.save('dictionary.gensim')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pXmbmms-eKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dad75766-46a4-46b6-f191-a312c7a624fd"
      },
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 5\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "ldamodel.save('model5.gensim')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}